{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/talat/anaconda3/envs/brobot/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/talat/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/talat/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import os\n",
    "import string\n",
    "import nltk\n",
    "import operator\n",
    "from numpy import array\n",
    "from itertools import islice\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_array(sentence):\n",
    "    word_list = sentence.split(' ')\n",
    "    \n",
    "    clean_word_list = []\n",
    "    for word in word_list:\n",
    "        op= word_filter(word)\n",
    "        if len(op) > 0:\n",
    "            clean_word_list.append(op)\n",
    "            \n",
    "    return clean-word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(word):\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    word = word.translate(translator)\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_filter(word):\n",
    "    \n",
    "    word = word.lower()\n",
    "    \n",
    "    word = remove_punctuations(word)\n",
    "    \n",
    "    # Remove stop words\n",
    "    stop_words = stopwords.words('english')\n",
    "    if word in stop_words:\n",
    "        return ''\n",
    "    \n",
    "    # Remove Common words\n",
    "    common_words = ['bid', 'offer', 'buy', 'sell', 'put', 'minus', 'plus', 'lifted', 'hit']\n",
    "    if word in common_words:\n",
    "        return ''\n",
    "    \n",
    "    # Remove numbers\n",
    "    if is_number(word):\n",
    "        return ''\n",
    "    \n",
    "    # Remove commas\n",
    "    word = word.replace(',','')\n",
    "    \n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_filter(sentence):\n",
    "    words = sentence.split(' ')\n",
    "    clean_sentence = []\n",
    "    for word in words:\n",
    "        word = word_filter(word)\n",
    "        if len(word) > 0:\n",
    "            clean_sentence.append(word)\n",
    "        \n",
    "    return ' '.join(clean_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_array_to_ixes(word_array, word_to_ixes):\n",
    "    \n",
    "    x_len = len(word_array) # Number of words in test\n",
    "    y_len = len(word_to_ixes) # Number of total vocab\n",
    "    \n",
    "    xs = [[0 for x in range(y_len)] for y in range(x_len)]\n",
    "    \n",
    "    # print(len(xs), len(xs[0]))\n",
    "    # print('xlen', x_len, 'ylen', y_len)\n",
    "    \n",
    "    for idx in range(x_len):\n",
    "        word = word_array[idx]\n",
    "        word_index = word_to_ixes[word]\n",
    "        # print('word', word, '- word_index', word_index, '- idx', idx)\n",
    "        xs[idx][word_index] = 1\n",
    "            \n",
    "    xs = array(xs)\n",
    "    return xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_text(filename, txt):\n",
    "    if os.path.exists(filename):\n",
    "        append_write = 'a' # append if already exists\n",
    "    else:\n",
    "        append_write = 'w' # make a new file if not\n",
    "        \n",
    "    with open(filename, append_write) as f:\n",
    "        f.write(txt + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "IP_FILEPATH = '../data/processed/rnn_aligned_1order_nsentence.csv'\n",
    "OP_ACCPRED_FILEPATH = '../data/processed/rnn_output_acc_pred.txt'\n",
    "OP_LOG_FILEPATH = '../data/processed/rnn_output_log.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    df_data = pd.read_csv(filename)\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19933, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>message</th>\n",
       "      <th>market</th>\n",
       "      <th>order_id</th>\n",
       "      <th>trader</th>\n",
       "      <th>broker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Hey Angelica, if you are there?</td>\n",
       "      <td>CAL</td>\n",
       "      <td>4549003</td>\n",
       "      <td>aeykens</td>\n",
       "      <td>mbennett</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Hey Marc, haha have never tried this chat here...</td>\n",
       "      <td>CAL</td>\n",
       "      <td>4549003</td>\n",
       "      <td>aeykens</td>\n",
       "      <td>mbennett</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>why hello there and good morn! if you are in</td>\n",
       "      <td>CAL</td>\n",
       "      <td>4549003</td>\n",
       "      <td>aeykens</td>\n",
       "      <td>mbennett</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Hi Marc, just cant get the hang of this chat h...</td>\n",
       "      <td>CAL</td>\n",
       "      <td>4549003</td>\n",
       "      <td>aeykens</td>\n",
       "      <td>mbennett</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>why hello there</td>\n",
       "      <td>CAL</td>\n",
       "      <td>4549003</td>\n",
       "      <td>aeykens</td>\n",
       "      <td>mbennett</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            message market  \\\n",
       "0           0                    Hey Angelica, if you are there?    CAL   \n",
       "1           1  Hey Marc, haha have never tried this chat here...    CAL   \n",
       "2           2       why hello there and good morn! if you are in    CAL   \n",
       "3           3  Hi Marc, just cant get the hang of this chat h...    CAL   \n",
       "4           4                                    why hello there    CAL   \n",
       "\n",
       "   order_id   trader    broker  \n",
       "0   4549003  aeykens  mbennett  \n",
       "1   4549003  aeykens  mbennett  \n",
       "2   4549003  aeykens  mbennett  \n",
       "3   4549003  aeykens  mbennett  \n",
       "4   4549003  aeykens  mbennett  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data\n",
    "df_data = read_data(IP_FILEPATH)\n",
    "print(df_data.shape)\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the message and market columns to string\n",
    "df_data['message'] = df_data['message'].astype(str)\n",
    "df_data['market'] = df_data['market'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input dataframe:  (19933, 6)\n"
     ]
    }
   ],
   "source": [
    "# Apply transformations \n",
    "# 1. Converting to a lower case\n",
    "df_data['message'] = df_data['message'].apply(lambda x: x.lower())\n",
    "df_data['market'] = df_data['market'].apply(lambda x: x.lower())\n",
    "print('Shape of input dataframe: ',df_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of filtered dataframe (19933, 6)\n"
     ]
    }
   ],
   "source": [
    "# Apply transformations \n",
    "# 2. Remove Filter words from message\n",
    "df_data['message'] = df_data['message'].apply(lambda x: sentence_filter(x))\n",
    "print('Shape of filtered dataframe', df_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of filtered dataframe (19933, 6)\n"
     ]
    }
   ],
   "source": [
    "# Apply transformations \n",
    "# 2. Remove Filter words from message\n",
    "df_data['market'] = df_data['market'].apply(lambda x: remove_punctuations(x))\n",
    "print('Shape of filtered dataframe', df_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after eliminating empty msgs:  (19286, 6)\n"
     ]
    }
   ],
   "source": [
    "# Clean the dataframe from empty messages\n",
    "df_data = df_data.loc[df_data['message'] != '']\n",
    "print('Shape after eliminating empty msgs: ', df_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>message</th>\n",
       "      <th>market</th>\n",
       "      <th>order_id</th>\n",
       "      <th>trader</th>\n",
       "      <th>broker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>hey angelica</td>\n",
       "      <td>cal</td>\n",
       "      <td>4549003</td>\n",
       "      <td>aeykens</td>\n",
       "      <td>mbennett</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>hey marc haha never tried chat sorry didnt not...</td>\n",
       "      <td>cal</td>\n",
       "      <td>4549003</td>\n",
       "      <td>aeykens</td>\n",
       "      <td>mbennett</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>hello good morn</td>\n",
       "      <td>cal</td>\n",
       "      <td>4549003</td>\n",
       "      <td>aeykens</td>\n",
       "      <td>mbennett</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>hi marc cant get hang chat haha</td>\n",
       "      <td>cal</td>\n",
       "      <td>4549003</td>\n",
       "      <td>aeykens</td>\n",
       "      <td>mbennett</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>hello</td>\n",
       "      <td>cal</td>\n",
       "      <td>4549003</td>\n",
       "      <td>aeykens</td>\n",
       "      <td>mbennett</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            message market  \\\n",
       "0           0                                       hey angelica    cal   \n",
       "1           1  hey marc haha never tried chat sorry didnt not...    cal   \n",
       "2           2                                    hello good morn    cal   \n",
       "3           3                    hi marc cant get hang chat haha    cal   \n",
       "4           4                                              hello    cal   \n",
       "\n",
       "   order_id   trader    broker  \n",
       "0   4549003  aeykens  mbennett  \n",
       "1   4549003  aeykens  mbennett  \n",
       "2   4549003  aeykens  mbennett  \n",
       "3   4549003  aeykens  mbennett  \n",
       "4   4549003  aeykens  mbennett  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in ../data/processed/rnn_aligned_1order_nsentence.csv is 7704\n",
      "Total number of words in ../data/processed/rnn_aligned_1order_nsentence.csv is 59856\n",
      "Number of unique targets in ../data/processed/rnn_aligned_1order_nsentence.csv is 79\n"
     ]
    }
   ],
   "source": [
    "sentences = df_data['message'].values\n",
    "possible_words = ' '.join(sentences)\n",
    "inputs_txt = possible_words.split(' ')\n",
    "vocab = list(set(inputs_txt))\n",
    "vocab_size = len(vocab)\n",
    "print('Number of unique words in %s is %d' % (IP_FILEPATH, vocab_size))\n",
    "print('Total number of words in %s is %d' % (IP_FILEPATH, len(inputs_txt)))\n",
    "\n",
    "targets_txt = df_data['market'].values\n",
    "target_vocab = list(set(targets_txt))\n",
    "target_vocab_size = len(target_vocab)\n",
    "print('Number of unique targets in %s is %d' % (IP_FILEPATH, target_vocab_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grouping by Trader Broker pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('aeykens', 'mbennett') ('aschnick', 'dvigna') ('aschnick', 'mbennett')\n",
      " ('bdavidson', 'mbennett') ('bdavidson', 'rbeckwermert')\n",
      " ('cbreen', 'csee') ('chuynh', 'dvigna') ('clove', 'dvigna')\n",
      " ('cmiller2', 'dvigna') ('divanics', 'jwidmer') ('edixon', 'msarosiak1')\n",
      " ('edixon3', 'csee') ('edixon3', 'jwidmer') ('edixon3', 'mbennett')\n",
      " ('edixon3', 'msarosiak1') ('edixon3', 'poregan') ('elambe', 'jwidmer')\n",
      " ('iwilliams', 'mbennett') ('jcrowe', 'csee') ('jcrowe', 'mbennett')\n",
      " ('jelliott', 'dvigna') ('jirsik', 'mbennett') ('jmorrow', 'mbennett')\n",
      " ('jmousse', 'msarosiak1') ('jtaton1', 'mbennett')\n",
      " ('jtaton1', 'rbeckwermert') ('khart', 'awakaluk') ('khart', 'jwidmer')\n",
      " ('khart', 'mbennett') ('khart', 'rbeckwermert') ('kkrug', 'cdouglas')\n",
      " ('kle', 'msarosiak1') ('lchou', 'mbennett') ('nmanuel', 'mbennett')\n",
      " ('nmanuel', 'rbeckwermert') ('sdimarzo1', 'cdouglas')\n",
      " ('sjaques', 'rbeckwermert') ('stischner', 'jwidmer')\n",
      " ('stischner', 'mbennett') ('tmcconnell', 'mbennett')\n",
      " ('tmcconnell', 'rbeckwermert') ('wgoodridge', 'cdouglas')\n",
      " ('wkunaman', 'dvigna') ('wkunaman', 'jwidmer') ('wolsen', 'dvigna')\n",
      " ('xgouldmarks2', 'msarosiak1')]\n"
     ]
    }
   ],
   "source": [
    "trader_broker_group = df_data.groupby(['trader', 'broker']).describe().index.values\n",
    "print(trader_broker_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionaries for Lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(words):\n",
    "    count = collections.Counter(words).most_common()\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return dictionary, reverse_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_ix, ix_to_word = build_dataset(inputs_txt)\n",
    "target_to_ix, ix_to_target = build_dataset(targets_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tb_dict(tb_array):\n",
    "    dictionary = dict()\n",
    "    for tb in tb_array:\n",
    "        dictionary[tb] = len(dictionary)\n",
    "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return dictionary, reverse_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the dictionary is  46\n"
     ]
    }
   ],
   "source": [
    "tb_to_ix, ix_to_tb = build_tb_dict(trader_broker_group)\n",
    "print('Length of the dictionary is ', len(tb_to_ix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trader_broker_pair_index(row):\n",
    "    return tb_to_ix[(row['trader'], row['broker'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply transformation\n",
    "# Create a new column in df_data to accommodate the index from the trader_broker pair dictionary\n",
    "df_data['trader_broker_idx'] = df_data.apply(get_trader_broker_pair_index, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>message</th>\n",
       "      <th>market</th>\n",
       "      <th>order_id</th>\n",
       "      <th>trader</th>\n",
       "      <th>broker</th>\n",
       "      <th>trader_broker_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19928</th>\n",
       "      <td>19928</td>\n",
       "      <td>ok bridge gap ice getting set aim</td>\n",
       "      <td>sw</td>\n",
       "      <td>4417103</td>\n",
       "      <td>xgouldmarks2</td>\n",
       "      <td>msarosiak1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19929</th>\n",
       "      <td>19929</td>\n",
       "      <td>got</td>\n",
       "      <td>sw</td>\n",
       "      <td>4417103</td>\n",
       "      <td>xgouldmarks2</td>\n",
       "      <td>msarosiak1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19930</th>\n",
       "      <td>19930</td>\n",
       "      <td>cheers</td>\n",
       "      <td>sw</td>\n",
       "      <td>4417103</td>\n",
       "      <td>xgouldmarks2</td>\n",
       "      <td>msarosiak1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19931</th>\n",
       "      <td>19931</td>\n",
       "      <td>get aim acct</td>\n",
       "      <td>sw</td>\n",
       "      <td>4417103</td>\n",
       "      <td>xgouldmarks2</td>\n",
       "      <td>msarosiak1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19932</th>\n",
       "      <td>19932</td>\n",
       "      <td>one sir handle ne2mikesarosiak</td>\n",
       "      <td>sw</td>\n",
       "      <td>4417103</td>\n",
       "      <td>xgouldmarks2</td>\n",
       "      <td>msarosiak1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                            message market  order_id  \\\n",
       "19928       19928  ok bridge gap ice getting set aim     sw   4417103   \n",
       "19929       19929                                got     sw   4417103   \n",
       "19930       19930                             cheers     sw   4417103   \n",
       "19931       19931                       get aim acct     sw   4417103   \n",
       "19932       19932     one sir handle ne2mikesarosiak     sw   4417103   \n",
       "\n",
       "             trader      broker  trader_broker_idx  \n",
       "19928  xgouldmarks2  msarosiak1                 45  \n",
       "19929  xgouldmarks2  msarosiak1                 45  \n",
       "19930  xgouldmarks2  msarosiak1                 45  \n",
       "19931  xgouldmarks2  msarosiak1                 45  \n",
       "19932  xgouldmarks2  msarosiak1                 45  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Test and Train Split - Stratified for Trader/Broker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_train_strat_tb(df, dict_ix_to_tb, test_size=0.2, min_total_size=10):\n",
    "    \n",
    "    df_train = pd.DataFrame(columns=df.columns.values)\n",
    "    df_test = pd.DataFrame(columns=df.columns.values)\n",
    "\n",
    "    for tb_idx in dict_ix_to_tb:\n",
    "        \n",
    "        df_tb_chats = df.loc[df['trader_broker_idx'] == tb_idx]\n",
    "        tb_indices = df_tb_chats.index.values        \n",
    "        num_rows = len(tb_indices)\n",
    "        \n",
    "        \n",
    "        test_count = round(num_rows * test_size)\n",
    "\n",
    "        test_sentence_ixes = np.random.choice(tb_indices, size=test_count, replace=False)\n",
    "        train_sentence_ixes = list(set(tb_indices) - set(test_sentence_ixes))\n",
    "\n",
    "        # print('TB Idx (%d) Instances Train, Test = %d, %d' % (tb_idx, len(train_sentence_ixes), len(test_sentence_ixes)))\n",
    "\n",
    "        df_train = df_train.append(df_data.loc[train_sentence_ixes], ignore_index=True)\n",
    "        df_test = df_test.append(df_data.loc[test_sentence_ixes], ignore_index=True)     \n",
    "            \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = generate_test_train_strat_tb(df_data, ix_to_tb, test_size=0.2, min_total_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape (15431, 7)\n",
      "Test shape (3855, 7)\n"
     ]
    }
   ],
   "source": [
    "print('Train shape', df_train.shape)\n",
    "print('Test shape', df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>message</th>\n",
       "      <th>market</th>\n",
       "      <th>order_id</th>\n",
       "      <th>trader</th>\n",
       "      <th>broker</th>\n",
       "      <th>trader_broker_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>hey angelica</td>\n",
       "      <td>cal</td>\n",
       "      <td>4549003</td>\n",
       "      <td>aeykens</td>\n",
       "      <td>mbennett</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>hello good morn</td>\n",
       "      <td>cal</td>\n",
       "      <td>4549003</td>\n",
       "      <td>aeykens</td>\n",
       "      <td>mbennett</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>hi marc cant get hang chat haha</td>\n",
       "      <td>cal</td>\n",
       "      <td>4549003</td>\n",
       "      <td>aeykens</td>\n",
       "      <td>mbennett</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>whats happening</td>\n",
       "      <td>cal</td>\n",
       "      <td>4549003</td>\n",
       "      <td>aeykens</td>\n",
       "      <td>mbennett</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>oh much old whats ice finally ice</td>\n",
       "      <td>cal</td>\n",
       "      <td>4549003</td>\n",
       "      <td>aeykens</td>\n",
       "      <td>mbennett</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0                            message market order_id   trader  \\\n",
       "0          0                       hey angelica    cal  4549003  aeykens   \n",
       "1          2                    hello good morn    cal  4549003  aeykens   \n",
       "2          3    hi marc cant get hang chat haha    cal  4549003  aeykens   \n",
       "3          5                    whats happening    cal  4549003  aeykens   \n",
       "4          6  oh much old whats ice finally ice    cal  4549003  aeykens   \n",
       "\n",
       "     broker trader_broker_idx  \n",
       "0  mbennett                 0  \n",
       "1  mbennett                 0  \n",
       "2  mbennett                 0  \n",
       "3  mbennett                 0  \n",
       "4  mbennett                 0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_vector(sentence, dict_word_to_ix):\n",
    "    words = sentence.split(' ')\n",
    "    sentence_vector = np.zeros((len(dict_word_to_ix),1))\n",
    "    \n",
    "    for word in words:\n",
    "        ix = dict_word_to_ix[word]\n",
    "        sentence_vector[ix] = 1\n",
    "        \n",
    "    return sentence_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data\n",
    "train_inputs = {}\n",
    "train_targets = {}\n",
    "train_tb_mapping = {}\n",
    "\n",
    "for idx, row in df_train.iterrows():\n",
    "    train_inputs[idx] = sentence_to_vector(row['message'], word_to_ix)\n",
    "    train_targets[idx] = target_to_ix[row['market'].strip()]\n",
    "    train_tb_mapping[idx] = row['trader_broker_idx']\n",
    "    \n",
    "    \n",
    "# Test Data\n",
    "test_inputs = {}\n",
    "test_targets = {}\n",
    "test_tb_mapping = {}\n",
    "\n",
    "for idx, row in df_train.iterrows():\n",
    "    test_inputs[idx] = sentence_to_vector(row['message'], word_to_ix)\n",
    "    test_targets[idx] = target_to_ix[row['market'].strip()]\n",
    "    test_tb_mapping[idx] = row['trader_broker_idx']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tb_ixes = np.unique(df_data['trader_broker_idx'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_to_vec(target, target_to_ix):\n",
    "    vec = np.zeros((len(target_to_ix), 1))\n",
    "    vec[target_to_ix[target]] = 1\n",
    "    \n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def targets_to_1vec(targets, target_to_ix):\n",
    "    vec = np.zeros((len(target_to_ix), 1))\n",
    "    \n",
    "    for target in targets:\n",
    "        vec[target_to_ix[target]] = 1\n",
    "    \n",
    "    return vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 100\n",
    "seq_length = 9 # Keeping the sequence length as 9 because the min chats to change the context is 10\n",
    "learning_rate = 1e-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model_parameters(hidden_size, input_vec_size, target_vec_size):\n",
    "    Wxh = np.random.randn(hidden_size, input_vec_size) * 0.01\n",
    "    Whh = np.random.randn(hidden_size, hidden_size) * 0.01\n",
    "    Why = np.random.randn(target_vocab_size, hidden_size) * 0.01\n",
    "\n",
    "    # Biases\n",
    "    bh = np.zeros((hidden_size, 1))\n",
    "    by = np.zeros((target_vocab_size, 1))\n",
    "\n",
    "    print('Wxh shape: ', Wxh.shape)\n",
    "    print('Whh shape: ', Whh.shape)\n",
    "    print('Why shape: ', Why.shape)\n",
    "\n",
    "    print('bh shape: ', bh.shape)\n",
    "    print('by shape: ', by.shape)\n",
    "    \n",
    "    return Wxh, Whh, Why, bh, by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wxh shape:  (100, 7704)\n",
      "Whh shape:  (100, 100)\n",
      "Why shape:  (79, 100)\n",
      "bh shape:  (100, 1)\n",
      "by shape:  (79, 1)\n"
     ]
    }
   ],
   "source": [
    "Wxh, Whh, Why, bh, by = initialize_model_parameters(hidden_size, vocab_size, target_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n",
    "\n",
    "Input:\n",
    "1. list of input words\n",
    "2. list of target words\n",
    "3. the previous hidden state\n",
    "\n",
    "Output:\n",
    "1. Loss\n",
    "2. Gradient for eah pareamters between layers\n",
    "3. Last hidden state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sample(h, seed_ix, n, op_filepath=None):\n",
    "def predict(h_values, df_test, target_vocab_size, ix_to_target, Wxh, Whh, Why, bh, by, op_filepath=None):\n",
    "    \n",
    "    # At a given iteration, sample a list of integers and generate statements\n",
    "    \n",
    "    # h = memory state - Initiailly after training of n samples, it is the hidden state of t iterations of training\n",
    "    # test_set - array - to be predicted\n",
    "    \n",
    "    predicted_values = []\n",
    "    \n",
    "    for idx, row in df_test.iterrows():\n",
    "        \n",
    "        inputs = row['message'] \n",
    "        target = row['market']\n",
    "        tb_idx = row['trader_broker_idx']\n",
    "        \n",
    "        h = h_values[tb_idx]\n",
    "                \n",
    "        x = sentence_to_vector(inputs, word_to_ix)\n",
    "        h = np.tanh(np.dot(Wxh, x) + np.dot(Whh, h) + bh)\n",
    "        y = np.dot(Why, h) + by\n",
    "        \n",
    "        # Compute the probabilities for the next words\n",
    "        p = np.exp(y) / np.sum(np.exp(y))\n",
    "        # print('p Shape :', p.shape)\n",
    "        \n",
    "        # Pick the output (here index) with the highest probabilities\n",
    "        ix = np.random.choice(range(target_vocab_size), p=p.ravel())\n",
    "        \n",
    "        targ = np.zeros((target_vocab_size, 1))\n",
    "        targ[ix] = 1\n",
    "        \n",
    "        targ = np.zeros((target_vocab_size, 1))\n",
    "        targ[ix] = 1\n",
    "        \n",
    "        predicted_value = ix_to_target[ix]\n",
    "        \n",
    "        if op_filepath is not None:\n",
    "            write_text(filename=op_filepath, txt=predicted_value+'\\n')\n",
    "        \n",
    "        # Add the predicted value to the list\n",
    "        predicted_values.append(predicted_value)\n",
    "        \n",
    "    print(predicted_values)\n",
    "    \n",
    "    return predicted_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_from_indices(ixes):\n",
    "    return ' '.join(ix_to_target[ix] for ix in ixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(predicted_output, ground_truth, op_filepath=None, iteration_count=0):\n",
    "    \n",
    "    '''\n",
    "    predicted_output = list of predictions that were generated by the RNN\n",
    "    ground_truth = outputs to which the accuracy is computed against\n",
    "    only_last_word = instead of computing the accuracy at each word, the accuracy is computed only for \n",
    "    the last word of the sentence\n",
    "    '''\n",
    "    \n",
    "    if len(predicted_output) != len(ground_truth):\n",
    "        print('Exception: The size of predicted output (%d) is different from ground truth (%d)' \n",
    "              % len(predicted_output), len(ground_truth))\n",
    "        return -1.00\n",
    "    \n",
    "    pred_length = len(predicted_output)\n",
    "    accurately_predicted = 0\n",
    "\n",
    "    for idx in range(pred_length):\n",
    "        \n",
    "        if op_filepath is not None:\n",
    "            write_text(filename=op_filepath, txt='pred:'+str(iteration_count)+':'+predicted_output[idx].strip()+'::'+ground_truth[idx].strip()+'\\n')\n",
    "        \n",
    "        if predicted_output[idx].strip() == ground_truth[idx].strip():\n",
    "            accurately_predicted += 1\n",
    "\n",
    "    accuracy = accurately_predicted / pred_length\n",
    "    \n",
    "    if op_filepath is not None:\n",
    "        write_text(filename=op_filepath, txt='acc:'+str(iteration_count)+':'+str(accuracy)+'\\n')\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xs[t] is the vector that encode the words at position t\n",
    "# ps[t] is the probabilities for next words\n",
    "\n",
    "def lossfn(input_vecs_T, target_indices, hprev, bh, by):\n",
    "    \n",
    "    '''\n",
    "    inputs = a string sentence\n",
    "    '''\n",
    "        \n",
    "    # Empty dictionaries\n",
    "    xs = {} # Store the 1-hot encoded input word vec\n",
    "    hs = {} # Hidden state outputs\n",
    "    ys = {} # Store the target variables\n",
    "    ps = {} # Noramized probabilities for the targets, ys\n",
    "    \n",
    "    hs[-1] = np.copy(hprev) # Creating a copy of hprev in the index -1 for chaining purposes\n",
    "    loss = 0\n",
    "    \n",
    "    # print('Input Vecs shape', input_vecs_T.shape)\n",
    "    # print('type of input_vecs', type(input_vecs_T))\n",
    "        \n",
    "    # Forward pass\n",
    "        \n",
    "    t = 0\n",
    "    for input_vec in input_vecs_T:\n",
    "                \n",
    "        input_vec = input_vec.transpose()\n",
    "        input_vec = input_vec.reshape(len(input_vec), 1)\n",
    "        \n",
    "        xs[t] = input_vec\n",
    "                \n",
    "        # print('Wxh shape', Wxh.shape)\n",
    "        # print('xs type', type(xs[t]))\n",
    "        # print('xs length', len(xs))\n",
    "        # print('Whh shape', Whh.shape) \n",
    "        # print('hs[t-1] shape', hs[t-1].shape)\n",
    "        # print('bh shape', bh.shape)\n",
    "        # print('Target Indices', target_indices)\n",
    "                \n",
    "        # Compute the hidden states\n",
    "        hs[t] = np.tanh(np.dot(Wxh, xs[t]) + np.dot(Whh, hs[t-1]) + bh)\n",
    "        \n",
    "        # Compute the target states\n",
    "        ys[t] = np.dot(Why, hs[t]) + by\n",
    "        \n",
    "        # probabilities for next words\n",
    "        ps[t] = np.exp(ys[t]) / np.sum(np.exp(ys[t]))  \n",
    "        \n",
    "        # Compute the log loss - Softmax (or cross entropy loss)\n",
    "        loss += -np.log(ps[t][target_indices[t], 0])\n",
    "        \n",
    "        t += 1\n",
    "        \n",
    "    # Back propagation\n",
    "    # Each weight & bias will have a gradient that is computed\n",
    "    # Declare some variables of the same shapes as the corresponding forward passes variables\n",
    "    dWxh = np.zeros_like(Wxh)\n",
    "    dWhh = np.zeros_like(Whh)\n",
    "    dWhy = np.zeros_like(Why)\n",
    "    \n",
    "    dbh = np.zeros_like(bh)\n",
    "    dby = np.zeros_like(by)\n",
    "    \n",
    "    dhnext = np.zeros_like(hs[0])\n",
    "    \n",
    "    # The gradient is computed from backward to the first --> in the reverse order\n",
    "    t = len(input_vecs_T)\n",
    "    for t in reversed(range(len(input_vecs_T))):\n",
    "        \n",
    "        # Output probabilities for the 't'th element in reverse order\n",
    "        dy = np.copy(ps[t])\n",
    "        \n",
    "        dy[target_indices[t]] -= 1\n",
    "        \n",
    "        dWhy += np.dot(dy, hs[t].T)\n",
    "        \n",
    "        dby += dy\n",
    "        \n",
    "        dh = np.dot(Why.T, dy) + dhnext # Backprop into h\n",
    "        \n",
    "        dhraw = (1 - hs[t] * hs[t]) * dh # Backprop through non-linearity\n",
    "        \n",
    "        bh += dhraw #derivative of hidden bias\n",
    "        \n",
    "        dWxh += np.dot(dhraw, xs[t].T) #derivative of input to hidden layer weight\n",
    "        dWhh += np.dot(dhraw, hs[t-1].T) #derivative of hidden layer to hidden layer weight\n",
    "        dhnext = np.dot(Whh.T, dhraw) \n",
    "  \n",
    "\n",
    "    for dparam in [dWxh, dWhh, dWhy, dbh, dby]:\n",
    "        np.clip(dparam, -5, 5, out=dparam) # clip to mitigate exploding gradients                                                                                                                 \n",
    "      \n",
    "    return loss, dWxh, dWhh, dWhy, dbh, dby, hs[len(input_vecs_T)-1]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = (0,[0.59979714])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-bcdc0a9d9bfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mwrite_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOP_LOG_FILEPATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mpred_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_vocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mix_to_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWxh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWhh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWhy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_filepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'../data/rnn_binary_pred_values.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0mtest_targets_txt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'market'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_targets_txt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_filepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOP_ACCPRED_FILEPATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-be07a7c58436>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(h_values, df_test, target_vocab_size, ix_to_target, Wxh, Whh, Why, bh, by, op_filepath)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mop_filepath\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mwrite_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mop_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtxt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredicted_value\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# Add the predicted value to the list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-23067ceb0167>\u001b[0m in \u001b[0;36mwrite_text\u001b[0;34m(filename, txt)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mappend_write\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;31m# make a new file if not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappend_write\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/brobot/lib/python3.6/_bootlocale.py\u001b[0m in \u001b[0;36mgetpreferredencoding\u001b[0;34m(do_setlocale)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlocale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpreferredencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo_setlocale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0mgetpreferredencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo_setlocale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdo_setlocale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_locale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnl_langinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_locale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCODESET\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "# p = 0\n",
    "\n",
    "# Memory variables for adagrad\n",
    "mWxh = np.zeros_like(Wxh)\n",
    "mWhh = np.zeros_like(Whh)\n",
    "mWhy = np.zeros_like(Why)\n",
    "\n",
    "mbh = np.zeros_like(bh)\n",
    "mby = np.zeros_like(by)\n",
    "\n",
    "smooth_loss = -np.log(1.0/vocab_size)*seq_length # loss at iteration 0 \n",
    "\n",
    "training_iter = 10e5\n",
    "sampling_iter = 1\n",
    "\n",
    "h_values = {}\n",
    "\n",
    "\n",
    "while n < training_iter:\n",
    "    \n",
    "    print('n', n)\n",
    "    \n",
    "    # INPUT/TARGETS - Prepare inputs\n",
    "    \n",
    "    # Get the indices of df_train in an array and use the seq_length rows at a time\n",
    "    \n",
    "    # If it is a start of the iteration of there are not enough samples for the end trailing block, reset p and h prev\n",
    "    # if n == 0 or p + seq_length+1 > len(train_inputs_txt):\n",
    "        # p = 0 # p = 0 is going back to the start of the data\n",
    "        # hprev = np.zeros((hidden_size, 1)) # At the start, the hidden state is initilized to 1\n",
    "    \n",
    "    prev_index = -1\n",
    "    \n",
    "    \n",
    "    for tb_pair in unique_tb_ixes:\n",
    "        df_train_sub = df_train.loc[df_train['trader_broker_idx'] == tb_pair]\n",
    "        \n",
    "        rows_num = len(df_train_sub)\n",
    "        cols_num = len(word_to_ix)\n",
    "        input_vecs = np.zeros((rows_num, cols_num))\n",
    "        target_indices = np.zeros(rows_num).astype(int)\n",
    "                \n",
    "        df_train_sub.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        for idx, row in df_train_sub.iterrows():\n",
    "            inputs = row['message'] \n",
    "            target = row['market']\n",
    "            input_vec = sentence_to_vector(inputs, word_to_ix)\n",
    "            \n",
    "            # print('Shape of input vectors ', input_vecs.shape)\n",
    "            # print('Shape of single input vector ', input_vec.shape)\n",
    "            input_vecs[idx] = input_vec.ravel()\n",
    "            \n",
    "            # print('Non-zeros in input_vec', np.count_nonzero(input_vec))\n",
    "            # print('Non-zeros in input_vecs', np.count_nonzero(input_vecs))\n",
    "            \n",
    "            target_index = target_to_ix[target]\n",
    "            target_indices[idx] = target_index\n",
    "            # print(target_index)\n",
    "            # print(target_indices)\n",
    "            \n",
    "        loss, dWxh, dWhh, dWhy, dbh, dby, hprev = lossfn(input_vecs, target_indices, hprev, bh, by)\n",
    "        smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
    "        \n",
    "        h_values[tb_idx] = hprev\n",
    "        \n",
    "        # OPTIMIZATION (ADAGRAD) perform parameter update with Adagrad                                                                                                                                                    \n",
    "        for param, dparam, mem in zip([Wxh, Whh, Why, bh, by],\n",
    "                                        [dWxh, dWhh, dWhy, dbh, dby],\n",
    "                                        [mWxh, mWhh, mWhy, mbh, mby]):\n",
    "            mem += dparam * dparam\n",
    "            param += -learning_rate * dparam / np.sqrt(mem + 1e-8) # adagrad update\n",
    "\n",
    "    '''\n",
    "    for idx, row in df_train.iterrows():\n",
    "        \n",
    "        inputs = row['message'] \n",
    "        target = row['market']\n",
    "        tb_idx = row['trader_broker_idx']\n",
    "        \n",
    "        if prev_index != tb_idx:\n",
    "            hprev = np.zeros((hidden_size, 1)) # At the start, the hidden state is initilized to 1\n",
    "            prev_index = tb_idx\n",
    "            # print('Context change: New trader broker pair', tb_idx)\n",
    "        \n",
    "        input_vec = sentence_to_vector(inputs, word_to_ix).transpose()        \n",
    "        target_index = target_to_ix[target]\n",
    "        target_indices = np.asarray(target_index)\n",
    "        target_indices = target_indices.reshape(1,1)        \n",
    "        \n",
    "        # inputs = [sentence_idx for ch in train_inputs_txt[p: p+seq_length]] # INPUTS\n",
    "        # targets = [target_to_ix[ch] for ch in train_targets_txt[p: p+seq_length]] # TARGETS\n",
    "    \n",
    "        # LOSS - Compute the loss\n",
    "        loss, dWxh, dWhh, dWhy, dbh, dby, hprev = lossfn(input_vec, target_indices, hprev, bh, by)\n",
    "        smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
    "        \n",
    "        h_values[tb_idx] = hprev\n",
    "        \n",
    "        # OPTIMIZATION (ADAGRAD) perform parameter update with Adagrad                                                                                                                                                    \n",
    "        for param, dparam, mem in zip([Wxh, Whh, Why, bh, by],\n",
    "                                        [dWxh, dWhh, dWhy, dbh, dby],\n",
    "                                        [mWxh, mWhh, mWhy, mbh, mby]):\n",
    "            mem += dparam * dparam\n",
    "            param += -learning_rate * dparam / np.sqrt(mem + 1e-8) # adagrad update\n",
    "    '''\n",
    "\n",
    "    # PREDICTION - Compute the predicted after every sampling_iter iterations\n",
    "    if n % sampling_iter == 0:\n",
    "\n",
    "        loss_string = 'Loss = (' + str(n) + ',' + str(smooth_loss) + ')'\n",
    "        print(loss_string) # print progress\n",
    "        write_text(OP_LOG_FILEPATH, loss_string)\n",
    "\n",
    "        pred_vals = predict(h_values, df_test, target_vocab_size, ix_to_target, Wxh, Whh, Why, bh, by, op_filepath='../data/rnn_binary_pred_values.txt')\n",
    "        test_targets_txt = df_test['market'].values\n",
    "        accuracy = compute_accuracy(pred_vals, test_targets_txt, op_filepath=OP_ACCPRED_FILEPATH, iteration_count=n)\n",
    "\n",
    "        acc_string = 'Acc = (' + str(n) + ',' + str(accuracy) + ')'\n",
    "        print(acc_string) # print progress\n",
    "        # write_text(OP_LOG_FILEPATH, acc_string)\n",
    "    \n",
    "    n += 1 # Counter for the iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brobot",
   "language": "python",
   "name": "brobot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
